{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreditScoringModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Credit Scoring Model\n",
        "\n",
        "On this occasion, Iâ€™m about to build a credit scoring model using two classification algorithms: Linear Regression and Decision Tree.\n",
        "\n",
        "- Linear regression is used because it is based on binary logit, the variable is a dummy variable that uses two possible values, 0 and 1.\n",
        "- Decision Tree is used because my mini-thesis and paper publication is about building a credit scoring model using a decision tree algorithm, referring to Credit scoring in banks and financial institutions via data mining techniques: A literature review (Sadatrasoul, et al. 2013)\n"
      ],
      "metadata": {
        "id": "x0PdmOfwRbLl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Import"
      ],
      "metadata": {
        "id": "PNj82NdiRlSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Libraries\n",
        "!pip install scikit-plot #used for visualizing confusion matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import scikitplot as skplt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression #for Logistic Regression method\n",
        "from sklearn import tree #for Decision Tree method\n",
        "from sklearn.model_selection import train_test_split #train test split data\n",
        "from sklearn.preprocessing import StandardScaler #data normalization on independent variable (X)\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "jyTxaUiKR8M8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "dfcredit = pd.read_excel(\"CreditScoringdataset.xlsx\")"
      ],
      "metadata": {
        "id": "FLSRtBGFRqs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Pre-processing Data"
      ],
      "metadata": {
        "id": "h-f5jRKGTvg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#displays the top 5 rows of the dataset.\n",
        "dfcredit.head()"
      ],
      "metadata": {
        "id": "4OKTfo4UT65a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove column \"ID\" because it is not a variable used in calculations/models\n",
        "dfcredit = dfcredit.drop('ID',axis=1) #axis=1 (remove all values from the column)"
      ],
      "metadata": {
        "id": "jptJpnQXVI7N"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#view data info\n",
        "dfcredit.info()"
      ],
      "metadata": {
        "id": "7JzB3yqYUeNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#view the number of missing values\n",
        "dfcredit.isna().sum() #isna() = view missing values, notna() = view filled values, sum() = count amount"
      ],
      "metadata": {
        "id": "vbFXQT0RUvOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fill in the missing value using the mean of each variable\n",
        "meaninqtimelast = dfcredit['InqTimeLast'].mean()\n",
        "meantlcnt = dfcredit['TLCnt'].mean()\n",
        "meantlsum = dfcredit['TLSum'].mean()\n",
        "meantlmaxsum = dfcredit['TLMaxSum'].mean()\n",
        "meantlsatcnt = dfcredit['TLSatCnt'].mean()\n",
        "meantl75utilcnt = dfcredit['TL75UtilCnt'].mean()\n",
        "meantl50utilcnt = dfcredit['TL50UtilCnt'].mean()\n",
        "meantlbalhcpct = dfcredit['TLBalHCPct'].mean()\n",
        "meantlsatpct = dfcredit['TLSatPct'].mean()\n",
        "meantlopenpct = dfcredit['TLOpenPct'].mean()\n",
        "meantlopen24pct = dfcredit['TLOpen24Pct'].mean()\n",
        "\n",
        "dfcredit['InqTimeLast'] = dfcredit['InqTimeLast'].fillna(meaninqtimelast)\n",
        "dfcredit['TLCnt'] = dfcredit['TLCnt'].fillna(meantlcnt)\n",
        "dfcredit['TLSum'] = dfcredit['TLSum'].fillna(meantlsum)\n",
        "dfcredit['TLMaxSum'] = dfcredit['TLMaxSum'].fillna(meantlmaxsum)\n",
        "dfcredit['TLSatCnt'] = dfcredit['TLSatCnt'].fillna(meantlsatcnt)\n",
        "dfcredit['TL75UtilCnt'] = dfcredit['TL75UtilCnt'].fillna(meantl75utilcnt)\n",
        "dfcredit['TL50UtilCnt'] = dfcredit['TL50UtilCnt'].fillna(meantl50utilcnt)\n",
        "dfcredit['TLBalHCPct'] = dfcredit['TLBalHCPct'].fillna(meantlbalhcpct)\n",
        "dfcredit['TLSatPct'] = dfcredit['TLSatPct'].fillna(meantlsatpct)\n",
        "dfcredit['TLOpenPct'] = dfcredit['TLOpenPct'].fillna(meantlopenpct)\n",
        "dfcredit['TLOpen24Pct'] = dfcredit['TLOpen24Pct'].fillna(meantlopen24pct)\n",
        "\n",
        "dfcredit.isna().sum()"
      ],
      "metadata": {
        "id": "6juK8-05WSYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Data Train & Data Test (Train Test Split)"
      ],
      "metadata": {
        "id": "-JMMG3E0iQSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split the dataset into 2 parts, data train and data test, y = target/label\n",
        "\n",
        "x = dfcredit.iloc[:, 1:29].values #variable x\n",
        "y = dfcredit.iloc[:, 0].values #variable y (TARGET)"
      ],
      "metadata": {
        "id": "Mkt8LyG2ifFG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split with 75% data train & 25% data test ratio\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0) #random state = to ensure that the model delivers consistent results every time it is run"
      ],
      "metadata": {
        "id": "icGLJU7wjXFp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Data Normalization\n",
        "Normalize the value of the independent variable (X) because it has a value with a different range, so it is normalized until the data is in the value from 0 to 1"
      ],
      "metadata": {
        "id": "Lkk8LQ3ds2-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datanorm = StandardScaler()\n",
        "x_train = datanorm.fit_transform(x_train)\n",
        "x_test = datanorm.transform(x_test)"
      ],
      "metadata": {
        "id": "WJ4bYtX9s77B"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Classification Model\n",
        "Algoritma:\n",
        "- Logistic Regression\n",
        "- Decision Tree"
      ],
      "metadata": {
        "id": "2JxFBctcuLDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "dflogreg =  LogisticRegression()\n",
        "dflogreg.fit(x_train, y_train)\n",
        "\n",
        "#Predict Data Test\n",
        "dflogreg_y = dflogreg.predict(x_test)\n",
        "\n",
        "#Confusion Matrix\n",
        "cm_dflogreg = confusion_matrix(y_test, dflogreg_y)\n",
        "cm_dflogreg"
      ],
      "metadata": {
        "id": "PM1LBwu5E1nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix Linear Regression Visualization\n",
        "skplt.metrics.plot_confusion_matrix(y_test, dflogreg_y)"
      ],
      "metadata": {
        "id": "LZ-eSyhld_Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree\n",
        "dftree =  tree.DecisionTreeClassifier(random_state=0)\n",
        "dftree.fit(x_train, y_train)\n",
        "\n",
        "#Predict Test Data\n",
        "dftree_y = dftree.predict(x_test)\n",
        "\n",
        "#Confusion Matrix\n",
        "cm_dftree = confusion_matrix(y_test, dftree_y)\n",
        "cm_dftree"
      ],
      "metadata": {
        "id": "dHxEIPDnFtY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix Decision Tree Visualization\n",
        "skplt.metrics.plot_confusion_matrix(y_test, dftree_y)"
      ],
      "metadata": {
        "id": "U18i5Ho2fg8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Performansi Model Confusion Matrix"
      ],
      "metadata": {
        "id": "4rTNoZ0ltsa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "print(accuracy_score(y_test, dflogreg_y))"
      ],
      "metadata": {
        "id": "1ey05mkzt1fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree\n",
        "print(accuracy_score(y_test, dftree_y))"
      ],
      "metadata": {
        "id": "0XKQHCrpGdMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Logistic Regression algorithm has a higher accuracy value than Decision Tree, so the model will continue to use the algorithm."
      ],
      "metadata": {
        "id": "VqXX6BKJ1U2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict & Probability Value of Logistic Regression\n",
        "logreg_pred = dflogreg.predict_proba(x_test)\n",
        "logreg_pred"
      ],
      "metadata": {
        "id": "TzM4JjOAIMVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combination Model of Probability, Predicted, and Actual Values\n",
        "\n",
        "dflogregprob = pd.DataFrame(logreg_pred, columns = ['goodloan_prob', 'defaulters_prob'])\n",
        "dflogregpred = pd.DataFrame(dflogreg.predict(x_test), columns = ['Predicted Value'])\n",
        "dflogregactual = pd.DataFrame(y_test,columns= ['Actual Value'])\n",
        "\n",
        "dfcreditprob=pd.concat([dflogregactual, dflogregprob, dflogregpred], axis=1)\n",
        "dfcreditprob.to_csv('CreditScoring_Probability.csv')\n",
        "dfcreditprob.head()"
      ],
      "metadata": {
        "id": "60Wq4CKPSW_a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}